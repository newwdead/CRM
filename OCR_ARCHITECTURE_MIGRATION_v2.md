# OCR Architecture Migration v2.0 - LayoutLMv3 + PaddleOCR

> **–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è**: October 26, 2025  
> **–í–µ—Ä—Å–∏—è**: 2.0.0  
> **–°—Ç–∞—Ç—É—Å**: üöÄ Planning Phase

---

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–û–±–∑–æ—Ä](#–æ–±–∑–æ—Ä)
2. [–¢–µ–∫—É—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞](#—Ç–µ–∫—É—â–∞—è-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
3. [–¶–µ–ª–µ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞](#—Ü–µ–ª–µ–≤–∞—è-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
4. [–ü–ª–∞–Ω –º–∏–≥—Ä–∞—Ü–∏–∏](#–ø–ª–∞–Ω-–º–∏–≥—Ä–∞—Ü–∏–∏)
5. [–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫](#—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π-—Å—Ç–µ–∫)
6. [–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞](#—Å—Ç—Ä—É–∫—Ç—É—Ä–∞-–ø—Ä–æ–µ–∫—Ç–∞)
7. [Roadmap](#roadmap)

---

## üéØ –û–±–∑–æ—Ä

### –ü—Ä–æ–±–ª–µ–º—ã —Ç–µ–∫—É—â–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

1. **–ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å** –ø—Ä–æ—Å—Ç–æ–≥–æ regex-–ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ—Å–ª–µ OCR
2. **–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏** –ø–æ–ª–µ–π –≤–∏–∑–∏—Ç–∫–∏
3. **–ù–µ—Ç –º–µ—Ö–∞–Ω–∏–∑–º–∞ –æ–±—É—á–µ–Ω–∏—è** –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
4. **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –≤–Ω–µ—à–Ω–∏—Ö API** (Parsio, Google Vision)
5. **–ù–µ—Ç —É—á–µ—Ç–∞ layout** –≤–∏–∑–∏—Ç–∫–∏ (—Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞)

### –¶–µ–ª–∏ –º–∏–≥—Ä–∞—Ü–∏–∏

1. ‚úÖ **–ü–æ–≤—ã—Å–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å** —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –¥–æ 95%+
2. ‚úÖ **–î–æ–±–∞–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é** —Å –ø–æ–º–æ—â—å—é LayoutLMv3
3. ‚úÖ **–°–æ–∑–¥–∞—Ç—å pipeline –æ–±—É—á–µ–Ω–∏—è** –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
4. ‚úÖ **–°–Ω–∏–∑–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç API** - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
5. ‚úÖ **–£–ª—É—á—à–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É layout** –≤–∏–∑–∏—Ç–æ–∫

---

## üèóÔ∏è –¢–µ–∫—É—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (v5.3.0)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   FastAPI    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     OCR      ‚îÇ
‚îÇ   (React)   ‚îÇ     ‚îÇ   Backend    ‚îÇ     ‚îÇ   Manager    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ                     ‚îÇ
                            ‚ñº                     ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  PostgreSQL  ‚îÇ     ‚îÇ  Providers:  ‚îÇ
                    ‚îÇ              ‚îÇ     ‚îÇ - Tesseract  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ - Parsio     ‚îÇ
                                         ‚îÇ - Google     ‚îÇ
                                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### –¢–µ–∫—É—â–∏–π flow –æ–±—Ä–∞–±–æ—Ç–∫–∏

1. **–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è** ‚Üí FastAPI endpoint
2. **QR –∫–æ–¥** ‚Üí –ü—Ä–æ–≤–µ—Ä–∫–∞ QR –∫–æ–¥–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
3. **OCR** ‚Üí –û–¥–∏–Ω –∏–∑ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ (Tesseract/Parsio/Google)
4. **Regex –ø–∞—Ä—Å–∏–Ω–≥** ‚Üí –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–µ–π (email, phone, name, etc.)
5. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ** ‚Üí PostgreSQL

### –ü—Ä–æ–±–ª–µ–º—ã

- ‚ùå Regex –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç
- ‚ùå –ù–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏—è layout –≤–∏–∑–∏—Ç–∫–∏
- ‚ùå –ù–µ—Ç –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- ‚ùå –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –≤–Ω–µ—à–Ω–∏—Ö API
- ‚ùå –ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –≤–∏–∑–∏—Ç–æ–∫

---

## üöÄ –¶–µ–ª–µ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ v2.0

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è | –ó–∞–¥–∞—á–∞ | –°—Ç–∞—Ç—É—Å |
|-----------|------------|--------|--------|
| **OCR** | PaddleOCR | –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ + bbox | ‚ö†Ô∏è –ß–∞—Å—Ç–∏—á–Ω–æ |
| **Layout Model** | LayoutLMv3 | –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–æ –ø–æ–ª—è–º | üî¥ –ù–æ–≤–æ–µ |
| **Validator** | FastAPI + spaCy/GPT | –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ | üü° Upgrade |
| **Training** | HuggingFace Transformers | –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π | üî¥ –ù–æ–≤–æ–µ |
| **Annotation** | Label Studio | –í–∏–∑—É–∞–ª—å–Ω–∞—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è | ‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω |
| **Storage** | PostgreSQL + MinIO | –î–∞–Ω–Ω—ã–µ + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è | üü° +MinIO |
| **Orchestration** | Docker Compose | –ò–∑–æ–ª—è—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤ | ‚úÖ –ï—Å—Ç—å |

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è —Å—Ö–µ–º–∞ v2.0

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Frontend (React)                          ‚îÇ
‚îÇ  ‚Ä¢ OCR Editor ‚Ä¢ Contact List ‚Ä¢ Duplicate Manager ‚Ä¢ Training UI  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     FastAPI Backend                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ   OCR API    ‚îÇ  ‚îÇ  Training    ‚îÇ  ‚îÇ  Validation  ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ   Endpoint   ‚îÇ  ‚îÇ     API      ‚îÇ  ‚îÇ     API      ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                  ‚îÇ                  ‚îÇ
          ‚ñº                  ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      ML Services Layer                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ  PaddleOCR   ‚îÇ  ‚îÇ  LayoutLMv3  ‚îÇ  ‚îÇ   Validator  ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ   Service    ‚îÇ  ‚îÇ   Service    ‚îÇ  ‚îÇ   (spaCy)    ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Text OCR   ‚îÇ  ‚îÇ ‚Ä¢ Field      ‚îÇ  ‚îÇ ‚Ä¢ Format     ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Bbox       ‚îÇ  ‚îÇ   Classify   ‚îÇ  ‚îÇ   Check      ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Multicard  ‚îÇ  ‚îÇ ‚Ä¢ Layout     ‚îÇ  ‚îÇ ‚Ä¢ Regex      ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ   Analysis   ‚îÇ  ‚îÇ ‚Ä¢ Correction ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                  ‚îÇ                  ‚îÇ
          ‚ñº                  ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Storage Layer                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ  PostgreSQL  ‚îÇ  ‚îÇ    MinIO     ‚îÇ  ‚îÇ    Redis     ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Contacts   ‚îÇ  ‚îÇ ‚Ä¢ Images     ‚îÇ  ‚îÇ ‚Ä¢ Cache      ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Training   ‚îÇ  ‚îÇ ‚Ä¢ Trained    ‚îÇ  ‚îÇ ‚Ä¢ Queue      ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ   Data       ‚îÇ  ‚îÇ   Models     ‚îÇ  ‚îÇ              ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚ñ≤
          ‚îÇ
          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Label Studio                                ‚îÇ
‚îÇ  ‚Ä¢ Manual Annotation ‚Ä¢ Ground Truth Creation ‚Ä¢ Model Training   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### –ù–æ–≤—ã–π flow –æ–±—Ä–∞–±–æ—Ç–∫–∏

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Upload     ‚îÇ
‚îÇ   Image      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  QR Check    ‚îÇ
‚îÇ  (Optional)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PaddleOCR   ‚îÇ  ‚Üê‚îÄ‚îÄ‚îÄ Step 1: Text Extraction + BBox
‚îÇ  ‚Ä¢ Text      ‚îÇ
‚îÇ  ‚Ä¢ Coords    ‚îÇ
‚îÇ  ‚Ä¢ Layout    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ LayoutLMv3   ‚îÇ  ‚Üê‚îÄ‚îÄ‚îÄ Step 2: Field Classification
‚îÇ  Classifier  ‚îÇ        (–ø–æ–Ω–∏–º–∞–µ—Ç layout + –∫–æ–Ω—Ç–µ–∫—Å—Ç)
‚îÇ              ‚îÇ
‚îÇ  Input:      ‚îÇ
‚îÇ  ‚Ä¢ Text      ‚îÇ
‚îÇ  ‚Ä¢ BBox      ‚îÇ
‚îÇ  ‚Ä¢ Image     ‚îÇ
‚îÇ              ‚îÇ
‚îÇ  Output:     ‚îÇ
‚îÇ  ‚Ä¢ full_name ‚îÇ
‚îÇ  ‚Ä¢ position  ‚îÇ
‚îÇ  ‚Ä¢ company   ‚îÇ
‚îÇ  ‚Ä¢ email     ‚îÇ
‚îÇ  ‚Ä¢ phone     ‚îÇ
‚îÇ  ‚Ä¢ website   ‚îÇ
‚îÇ  ‚Ä¢ address   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Validator   ‚îÇ  ‚Üê‚îÄ‚îÄ‚îÄ Step 3: Format Check & Correction
‚îÇ  ‚Ä¢ Email     ‚îÇ
‚îÇ  ‚Ä¢ Phone     ‚îÇ
‚îÇ  ‚Ä¢ URL       ‚îÇ
‚îÇ  ‚Ä¢ NER       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Save      ‚îÇ
‚îÇ  PostgreSQL  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìã –ü–ª–∞–Ω –º–∏–≥—Ä–∞—Ü–∏–∏

### –≠—Ç–∞–ø 0: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ (1-2 –Ω–µ–¥–µ–ª–∏)

#### 0.1 –ê–Ω–∞–ª–∏–∑ –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
- [x] –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- [x] –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø–ª–∞–Ω–∞
- [ ] –û—Ü–µ–Ω–∫–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ —Ä–µ—Å—É—Ä—Å–∞–º (CPU/GPU/RAM)
- [ ] –í—ã–±–æ—Ä –≤–µ—Ä—Å–∏–∏ LayoutLMv3 (base/large)

#### 0.2 –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞
- [ ] –£—Å—Ç–∞–Ω–æ–≤–∫–∞ MinIO –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- [ ] –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Label Studio –¥–ª—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
- [ ] –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ GPU (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
- [ ] –°–æ–∑–¥–∞–Ω–∏–µ dev –æ–∫—Ä—É–∂–µ–Ω–∏—è

#### 0.3 Data Preparation
- [ ] –≠–∫—Å–ø–æ—Ä—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
- [ ] –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ training/validation split
- [ ] –°–æ–∑–¥–∞–Ω–∏–µ schema –¥–ª—è Label Studio
- [ ] Baseline –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è (100+ –≤–∏–∑–∏—Ç–æ–∫)

**Deliverables:**
- ‚úÖ `OCR_ARCHITECTURE_MIGRATION_v2.md` (—ç—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç)
- ‚¨ú MinIO –≤ docker-compose
- ‚¨ú Label Studio project –Ω–∞—Å—Ç—Ä–æ–µ–Ω
- ‚¨ú Dataset –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (100+ –æ–±—Ä–∞–∑—Ü–æ–≤)

---

### –≠—Ç–∞–ø 1: PaddleOCR Integration (2-3 –Ω–µ–¥–µ–ª–∏)

#### 1.1 –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PaddleOCR
```bash
# backend/requirements.txt
paddlepaddle==2.5.0  # CPU version
# paddlepaddle-gpu==2.5.0  # GPU version (–µ—Å–ª–∏ –µ—Å—Ç—å GPU)
paddleocr==2.7.0
```

#### 1.2 –°–æ–∑–¥–∞–Ω–∏–µ PaddleOCR Provider
```python
# backend/app/integrations/ocr/providers/paddle_provider.py
from paddleocr import PaddleOCR
import numpy as np
from PIL import Image

class PaddleOCRProvider(OCRProvider):
    """PaddleOCR - –≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å + bbox + layout"""
    
    def __init__(self):
        super().__init__("PaddleOCR")
        self.priority = 0  # –ù–∞–∏–≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        self.ocr = PaddleOCR(
            use_angle_cls=True,  # –ü–æ–≤–æ—Ä–æ—Ç —Ç–µ–∫—Å—Ç–∞
            lang='en',           # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å 'ru', 'ch'
            use_gpu=False,       # True –µ—Å–ª–∏ –µ—Å—Ç—å GPU
            show_log=False
        )
    
    def is_available(self) -> bool:
        return True  # –í—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ
    
    def recognize(self, image_data: bytes, filename: str = None) -> Dict[str, Any]:
        """
        –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å PaddleOCR
        
        Returns:
            {
                'provider': 'PaddleOCR',
                'raw_text': str,
                'blocks': [
                    {
                        'text': str,
                        'bbox': [[x1,y1], [x2,y2], [x3,y3], [x4,y4]],
                        'confidence': float
                    }
                ],
                'data': {...},  # Parsed fields
                'confidence': float
            }
        """
        # Convert bytes to numpy array
        img = Image.open(io.BytesIO(image_data))
        img_np = np.array(img)
        
        # Run OCR
        result = self.ocr.ocr(img_np, cls=True)
        
        # Extract blocks with bboxes
        blocks = []
        all_text = []
        
        for line in result[0]:
            bbox, (text, confidence) = line
            blocks.append({
                'text': text,
                'bbox': bbox,
                'confidence': confidence
            })
            all_text.append(text)
        
        combined_text = '\n'.join(all_text)
        
        return {
            'provider': self.name,
            'raw_text': combined_text,
            'blocks': blocks,  # NEW: Structured blocks with coordinates
            'data': self._parse_text(combined_text),
            'confidence': np.mean([b['confidence'] for b in blocks]) if blocks else 0
        }
```

#### 1.3 –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ OCRManager
```python
# backend/app/integrations/ocr/providers.py
from .paddle_provider import PaddleOCRProvider

class OCRManager:
    def _initialize_providers(self):
        all_providers = [
            PaddleOCRProvider(),        # ‚Üê NEW: Priority 0
            ParsioProvider(),           # Priority 1
            GoogleVisionProvider(),     # Priority 2
            TesseractProvider(),        # Priority 3
        ]
```

#### 1.4 –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- [ ] Unit tests –¥–ª—è PaddleOCRProvider
- [ ] Integration tests —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –≤–∏–∑–∏—Ç–∫–∞–º–∏
- [ ] Benchmark: —Ç–æ—á–Ω–æ—Å—Ç—å vs Tesseract/Google
- [ ] Performance: —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏

**Deliverables:**
- ‚¨ú `paddle_provider.py` —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω
- ‚¨ú –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω –≤ OCRManager
- ‚¨ú Tests –ø—Ä–æ—Ö–æ–¥—è—Ç (90%+ coverage)
- ‚¨ú Benchmark –æ—Ç—á–µ—Ç

---

### –≠—Ç–∞–ø 2: LayoutLMv3 Integration (3-4 –Ω–µ–¥–µ–ª–∏)

#### 2.1 –£—Å—Ç–∞–Ω–æ–≤–∫–∞ LayoutLMv3
```bash
# backend/requirements.txt
transformers==4.35.0
torch==2.1.0  # CPU version
# torch==2.1.0+cu118  # GPU version
pillow==10.1.0
numpy==1.24.0
```

#### 2.2 –°–æ–∑–¥–∞–Ω–∏–µ LayoutLMv3 Service
```python
# backend/app/services/layoutlm_service.py
from transformers import LayoutLMv3Processor, LayoutLMv3ForTokenClassification
import torch
from PIL import Image

class LayoutLMv3Service:
    """
    Service for field classification using LayoutLMv3
    
    Model understands:
    - Text content
    - Spatial layout (bbox)
    - Visual features (image)
    """
    
    def __init__(self, model_path: str = None):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # Load pre-trained model or fine-tuned model
        model_name = model_path or "microsoft/layoutlmv3-base"
        
        self.processor = LayoutLMv3Processor.from_pretrained(model_name)
        self.model = LayoutLMv3ForTokenClassification.from_pretrained(model_name)
        self.model.to(self.device)
        self.model.eval()
        
        # Label mapping for business cards
        self.id2label = {
            0: 'O',          # Other
            1: 'B-NAME',     # Begin Name
            2: 'I-NAME',     # Inside Name
            3: 'B-POSITION', # Begin Position
            4: 'I-POSITION',
            5: 'B-COMPANY',
            6: 'I-COMPANY',
            7: 'B-EMAIL',
            8: 'B-PHONE',
            9: 'I-PHONE',
            10: 'B-ADDRESS',
            11: 'I-ADDRESS',
            12: 'B-WEBSITE',
        }
        
        self.label2id = {v: k for k, v in self.id2label.items()}
    
    def classify_fields(
        self,
        image: Image.Image,
        ocr_blocks: List[Dict]
    ) -> Dict[str, Any]:
        """
        Classify OCR blocks into business card fields
        
        Args:
            image: PIL Image
            ocr_blocks: List of dicts with 'text' and 'bbox' from PaddleOCR
        
        Returns:
            {
                'full_name': str,
                'position': str,
                'company': str,
                'email': str,
                'phone': str,
                'address': str,
                'website': str,
                'confidence': float,
                'predictions': List[Dict]  # Raw predictions
            }
        """
        # Prepare input for LayoutLMv3
        words = [block['text'] for block in ocr_blocks]
        boxes = [self._normalize_bbox(block['bbox'], image.size) for block in ocr_blocks]
        
        # Encode
        encoding = self.processor(
            image,
            words,
            boxes=boxes,
            return_tensors="pt",
            padding="max_length",
            truncation=True
        )
        
        # Move to device
        encoding = {k: v.to(self.device) for k, v in encoding.items()}
        
        # Inference
        with torch.no_grad():
            outputs = self.model(**encoding)
            predictions = outputs.logits.argmax(-1).squeeze().tolist()
        
        # Decode predictions
        classified_fields = self._decode_predictions(
            words,
            predictions,
            ocr_blocks
        )
        
        return classified_fields
    
    def _normalize_bbox(self, bbox, image_size):
        """
        Normalize bbox coordinates to [0, 1000] scale
        LayoutLMv3 expects: [x_min, y_min, x_max, y_max]
        """
        width, height = image_size
        
        # Extract coordinates from PaddleOCR format
        x_coords = [point[0] for point in bbox]
        y_coords = [point[1] for point in bbox]
        
        x_min = min(x_coords)
        x_max = max(x_coords)
        y_min = min(y_coords)
        y_max = max(y_coords)
        
        # Normalize to 1000x1000
        return [
            int(x_min / width * 1000),
            int(y_min / height * 1000),
            int(x_max / width * 1000),
            int(y_max / height * 1000)
        ]
    
    def _decode_predictions(
        self,
        words: List[str],
        predictions: List[int],
        ocr_blocks: List[Dict]
    ) -> Dict[str, Any]:
        """
        Decode model predictions into structured contact fields
        """
        # Group words by predicted labels
        field_map = {
            'full_name': [],
            'position': [],
            'company': [],
            'email': [],
            'phone': [],
            'address': [],
            'website': []
        }
        
        current_field = None
        
        for i, (word, pred_id) in enumerate(zip(words, predictions)):
            label = self.id2label.get(pred_id, 'O')
            
            if label == 'O':
                current_field = None
                continue
            
            # Parse label (e.g., 'B-NAME' -> 'NAME')
            bio, field_type = label.split('-')
            
            # Map to our field names
            field_name_map = {
                'NAME': 'full_name',
                'POSITION': 'position',
                'COMPANY': 'company',
                'EMAIL': 'email',
                'PHONE': 'phone',
                'ADDRESS': 'address',
                'WEBSITE': 'website'
            }
            
            field_name = field_name_map.get(field_type)
            if not field_name:
                continue
            
            if bio == 'B':  # Begin
                current_field = field_name
                field_map[field_name].append(word)
            elif bio == 'I' and current_field == field_name:  # Inside
                field_map[field_name].append(word)
        
        # Join words into strings
        result = {
            field: ' '.join(words) if words else None
            for field, words in field_map.items()
        }
        
        # Calculate confidence (simplified)
        confidence = len([w for w in words if w]) / len(words) if words else 0
        
        result['confidence'] = confidence
        result['predictions'] = [
            {
                'word': word,
                'label': self.id2label.get(pred_id, 'O'),
                'bbox': ocr_blocks[i]['bbox']
            }
            for i, (word, pred_id) in enumerate(zip(words, predictions))
        ]
        
        return result
```

#### 2.3 Integration —Å OCR Pipeline
```python
# backend/app/tasks.py

from .services.layoutlm_service import LayoutLMv3Service

# Initialize LayoutLMv3 service (singleton)
layoutlm_service = LayoutLMv3Service()

def _process_card_sync(...):
    # ... QR code check ...
    
    # Step 1: PaddleOCR for text + bbox
    ocr_result = ocr_manager.recognize(
        ocr_input,
        filename=filename,
        preferred_provider='paddleocr'  # Force PaddleOCR
    )
    
    # Step 2: LayoutLMv3 for field classification
    if 'blocks' in ocr_result and ocr_result['blocks']:
        img = Image.open(io.BytesIO(image_data))
        
        classified_data = layoutlm_service.classify_fields(
            image=img,
            ocr_blocks=ocr_result['blocks']
        )
        
        # Use classified data instead of regex parsing
        data = classified_data
        recognition_method = 'paddleocr_layoutlm'
    else:
        # Fallback to old method
        data = ocr_result['data']
        recognition_method = ocr_result['provider']
```

#### 2.4 –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- [ ] Unit tests –¥–ª—è LayoutLMv3Service
- [ ] Integration tests —Å PaddleOCR
- [ ] Benchmark: —Ç–æ—á–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ–ª–µ–π
- [ ] A/B testing —Å —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–µ–π

**Deliverables:**
- ‚¨ú `layoutlm_service.py` —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω
- ‚¨ú –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω –≤ OCR pipeline
- ‚¨ú Tests –ø—Ä–æ—Ö–æ–¥—è—Ç
- ‚¨ú A/B test –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —É–ª—É—á—à–µ–Ω–∏–µ

---

### –≠—Ç–∞–ø 3: Validator & Post-processing (1-2 –Ω–µ–¥–µ–ª–∏)

#### 3.1 –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
```bash
# backend/requirements.txt
spacy==3.7.0
# python -m spacy download en_core_web_sm
# python -m spacy download ru_core_news_sm
phonenumbers==8.13.0
email-validator==2.1.0
```

#### 3.2 –°–æ–∑–¥–∞–Ω–∏–µ Validator Service
```python
# backend/app/services/validator_service.py
import re
import spacy
import phonenumbers
from email_validator import validate_email, EmailNotValidError
from typing import Dict, Optional

class ValidatorService:
    """
    Service for validating and correcting extracted contact fields
    """
    
    def __init__(self):
        self.nlp_en = spacy.load('en_core_web_sm')
        # self.nlp_ru = spacy.load('ru_core_news_sm')  # If needed
    
    def validate_and_correct(self, data: Dict[str, Optional[str]]) -> Dict[str, Optional[str]]:
        """
        Validate and correct all fields
        
        Returns corrected data
        """
        corrected = data.copy()
        
        # Email validation
        if corrected.get('email'):
            corrected['email'] = self._validate_email(corrected['email'])
        
        # Phone validation
        if corrected.get('phone'):
            corrected['phone'] = self._validate_phone(corrected['phone'])
        
        # Website validation
        if corrected.get('website'):
            corrected['website'] = self._validate_website(corrected['website'])
        
        # Name validation (use NER if needed)
        if corrected.get('full_name'):
            corrected['full_name'] = self._validate_name(corrected['full_name'])
        
        return corrected
    
    def _validate_email(self, email: str) -> Optional[str]:
        """Validate and normalize email"""
        try:
            valid = validate_email(email, check_deliverability=False)
            return valid.email
        except EmailNotValidError:
            # Try to extract email from text
            email_pattern = r'[\w\.-]+@[\w\.-]+\.[a-zA-Z]{2,}'
            match = re.search(email_pattern, email)
            return match.group(0) if match else None
    
    def _validate_phone(self, phone: str) -> Optional[str]:
        """Validate and normalize phone number"""
        try:
            # Parse phone number
            parsed = phonenumbers.parse(phone, None)
            
            if phonenumbers.is_valid_number(parsed):
                # Format in international format
                return phonenumbers.format_number(
                    parsed,
                    phonenumbers.PhoneNumberFormat.INTERNATIONAL
                )
        except:
            pass
        
        # Fallback: clean up phone number
        cleaned = re.sub(r'[^\d+]', '', phone)
        return cleaned if len(cleaned) >= 7 else None
    
    def _validate_website(self, website: str) -> Optional[str]:
        """Validate and normalize website"""
        # Add http:// if missing
        if not website.startswith(('http://', 'https://')):
            website = 'https://' + website
        
        # Basic URL validation
        url_pattern = r'https?://[^\s]+'
        if re.match(url_pattern, website):
            return website
        
        return None
    
    def _validate_name(self, name: str) -> Optional[str]:
        """Validate name using NER"""
        # Use spaCy NER to check if it looks like a name
        doc = self.nlp_en(name)
        
        # Check if any entities are detected as PERSON
        persons = [ent.text for ent in doc.ents if ent.label_ == 'PERSON']
        
        if persons:
            return persons[0]  # Return the first person name found
        
        # Fallback: just clean up the name
        return name.strip()
```

#### 3.3 Integration
```python
# backend/app/tasks.py

validator_service = ValidatorService()

def _process_card_sync(...):
    # ... OCR + LayoutLM ...
    
    # Step 3: Validation and correction
    data = validator_service.validate_and_correct(data)
    
    # ... save to database ...
```

**Deliverables:**
- ‚¨ú `validator_service.py` —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω
- ‚¨ú Tests –ø—Ä–æ—Ö–æ–¥—è—Ç
- ‚¨ú –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ pipeline

---

### –≠—Ç–∞–ø 4: Training Pipeline (3-4 –Ω–µ–¥–µ–ª–∏)

#### 4.1 Label Studio Configuration

```xml
<!-- label-studio-config.xml -->
<View>
  <Image name="image" value="$image"/>
  <Labels name="label" toName="image">
    <Label value="NAME" background="red"/>
    <Label value="POSITION" background="blue"/>
    <Label value="COMPANY" background="green"/>
    <Label value="EMAIL" background="purple"/>
    <Label value="PHONE" background="orange"/>
    <Label value="ADDRESS" background="yellow"/>
    <Label value="WEBSITE" background="cyan"/>
  </Labels>
  <Rectangle name="bbox" toName="image" strokeWidth="3"/>
  <Text name="transcription" toName="image" editable="true"/>
</View>
```

#### 4.2 Data Export Pipeline
```python
# backend/app/services/training_service.py

class TrainingService:
    """
    Service for managing training data and model fine-tuning
    """
    
    def export_for_labeling(self, contact_ids: List[int]) -> str:
        """
        Export contacts to Label Studio format
        
        Returns: Path to exported JSON file
        """
        # Get contacts from database
        contacts = self.db.query(Contact).filter(
            Contact.id.in_(contact_ids)
        ).all()
        
        # Convert to Label Studio format
        tasks = []
        for contact in contacts:
            task = {
                'data': {
                    'image': f'/label-studio/files/{contact.photo_path}'
                },
                'predictions': [{
                    'result': self._contact_to_annotations(contact)
                }]
            }
            tasks.append(task)
        
        # Save to file
        output_path = f'/tmp/export_{uuid.uuid4().hex}.json'
        with open(output_path, 'w') as f:
            json.dump(tasks, f)
        
        return output_path
    
    def import_annotations(self, label_studio_export: str):
        """
        Import annotations from Label Studio
        
        Creates training dataset for LayoutLMv3
        """
        # Load Label Studio export
        with open(label_studio_export, 'r') as f:
            tasks = json.load(f)
        
        # Convert to LayoutLMv3 training format
        training_data = []
        
        for task in tasks:
            image_path = task['data']['image']
            annotations = task['annotations'][0]['result']
            
            # Parse annotations
            training_example = self._parse_annotations(
                image_path,
                annotations
            )
            
            training_data.append(training_example)
        
        # Save training dataset
        dataset_path = f'/app/training_data/dataset_{int(time.time())}.json'
        with open(dataset_path, 'w') as f:
            json.dump(training_data, f)
        
        return dataset_path
    
    def fine_tune_model(
        self,
        training_data_path: str,
        base_model: str = 'microsoft/layoutlmv3-base',
        epochs: int = 10,
        batch_size: int = 4
    ):
        """
        Fine-tune LayoutLMv3 model on training data
        """
        # Load training data
        with open(training_data_path, 'r') as f:
            training_data = json.load(f)
        
        # Create HuggingFace dataset
        from datasets import Dataset
        dataset = Dataset.from_dict(training_data)
        
        # Split train/val
        dataset = dataset.train_test_split(test_size=0.1)
        
        # Load model and tokenizer
        from transformers import (
            LayoutLMv3ForTokenClassification,
            LayoutLMv3Processor,
            Trainer,
            TrainingArguments
        )
        
        processor = LayoutLMv3Processor.from_pretrained(base_model)
        model = LayoutLMv3ForTokenClassification.from_pretrained(
            base_model,
            num_labels=len(self.label2id)
        )
        
        # Training arguments
        training_args = TrainingArguments(
            output_dir='/app/models/layoutlmv3_finetuned',
            num_train_epochs=epochs,
            per_device_train_batch_size=batch_size,
            per_device_eval_batch_size=batch_size,
            warmup_steps=500,
            weight_decay=0.01,
            logging_dir='/app/logs',
            logging_steps=10,
            eval_strategy="epoch",
            save_strategy="epoch",
            load_best_model_at_end=True,
        )
        
        # Create trainer
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=dataset['train'],
            eval_dataset=dataset['test'],
            tokenizer=processor,
        )
        
        # Train
        trainer.train()
        
        # Save model
        model_path = f'/app/models/layoutlmv3_finetuned_{int(time.time())}'
        trainer.save_model(model_path)
        
        return model_path
```

#### 4.3 API Endpoints –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
```python
# backend/app/api/training.py

from fastapi import APIRouter, Depends, UploadFile, File
from ..services.training_service import TrainingService

router = APIRouter(prefix="/api/training", tags=["training"])

@router.post("/export")
async def export_for_labeling(
    contact_ids: List[int],
    service: TrainingService = Depends(get_training_service)
):
    """Export contacts to Label Studio format"""
    export_path = service.export_for_labeling(contact_ids)
    return {"export_path": export_path}

@router.post("/import")
async def import_annotations(
    file: UploadFile = File(...),
    service: TrainingService = Depends(get_training_service)
):
    """Import annotations from Label Studio"""
    # Save uploaded file
    temp_path = f'/tmp/{file.filename}'
    with open(temp_path, 'wb') as f:
        f.write(await file.read())
    
    dataset_path = service.import_annotations(temp_path)
    return {"dataset_path": dataset_path}

@router.post("/train")
async def train_model(
    dataset_path: str,
    epochs: int = 10,
    service: TrainingService = Depends(get_training_service)
):
    """Start model training"""
    model_path = service.fine_tune_model(
        training_data_path=dataset_path,
        epochs=epochs
    )
    return {"model_path": model_path}
```

**Deliverables:**
- ‚¨ú Label Studio –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–ª—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
- ‚¨ú `training_service.py` —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω
- ‚¨ú API endpoints –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
- ‚¨ú –û–±—É—á–µ–Ω–∞ –ø–µ—Ä–≤–∞—è –≤–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏

---

### –≠—Ç–∞–ø 5: MinIO Integration (1 –Ω–µ–¥–µ–ª—è)

#### 5.1 Docker Compose Setup
```yaml
# docker-compose.yml

services:
  minio:
    image: minio/minio:latest
    container_name: bizcard-minio
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-admin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minio123456}
    volumes:
      - minio_data:/data
    ports:
      - '127.0.0.1:9000:9000'  # API
      - '127.0.0.1:9001:9001'  # Console
    command: server /data --console-address ":9001"
    restart: unless-stopped

volumes:
  minio_data:
```

#### 5.2 MinIO Client Service
```python
# backend/app/services/storage_service.py

from minio import Minio
from minio.error import S3Error
import io

class StorageService:
    """
    Service for managing file storage in MinIO
    """
    
    def __init__(self):
        self.client = Minio(
            os.getenv('MINIO_ENDPOINT', 'minio:9000'),
            access_key=os.getenv('MINIO_ROOT_USER', 'admin'),
            secret_key=os.getenv('MINIO_ROOT_PASSWORD'),
            secure=False  # Use True in production with SSL
        )
        
        # Create buckets if they don't exist
        self._ensure_buckets()
    
    def _ensure_buckets(self):
        """Create required buckets"""
        buckets = ['business-cards', 'trained-models', 'training-data']
        
        for bucket in buckets:
            if not self.client.bucket_exists(bucket):
                self.client.make_bucket(bucket)
    
    def upload_image(self, image_data: bytes, filename: str) -> str:
        """
        Upload business card image to MinIO
        
        Returns: Object path (bucket/filename)
        """
        bucket = 'business-cards'
        
        self.client.put_object(
            bucket,
            filename,
            io.BytesIO(image_data),
            length=len(image_data),
            content_type='image/jpeg'
        )
        
        return f'{bucket}/{filename}'
    
    def get_image(self, object_path: str) -> bytes:
        """Get image from MinIO"""
        bucket, filename = object_path.split('/', 1)
        
        response = self.client.get_object(bucket, filename)
        data = response.read()
        response.close()
        response.release_conn()
        
        return data
    
    def upload_model(self, model_path: str, model_name: str) -> str:
        """Upload trained model to MinIO"""
        bucket = 'trained-models'
        
        self.client.fput_object(
            bucket,
            model_name,
            model_path
        )
        
        return f'{bucket}/{model_name}'
```

**Deliverables:**
- ‚¨ú MinIO –¥–æ–±–∞–≤–ª–µ–Ω –≤ docker-compose
- ‚¨ú `storage_service.py` —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω
- ‚¨ú –ú–∏–≥—Ä–∞—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

---

### –≠—Ç–∞–ø 6: Frontend Integration (2 –Ω–µ–¥–µ–ª–∏)

#### 6.1 Training UI Component
```javascript
// frontend/src/components/TrainingPanel.js

import React, { useState } from 'react';
import axios from 'axios';

const TrainingPanel = () => {
  const [selectedContacts, setSelectedContacts] = useState([]);
  const [training, setTraining] = useState(false);
  
  const exportForLabeling = async () => {
    const response = await axios.post('/api/training/export', {
      contact_ids: selectedContacts
    });
    
    // Open Label Studio with exported data
    window.open(`http://localhost:8081/projects/1`, '_blank');
  };
  
  const startTraining = async () => {
    setTraining(true);
    
    const response = await axios.post('/api/training/train', {
      dataset_path: '/app/training_data/latest.json',
      epochs: 10
    });
    
    setTraining(false);
    alert('Training completed! Model saved to: ' + response.data.model_path);
  };
  
  return (
    <div className="training-panel">
      <h2>Model Training</h2>
      
      <button onClick={exportForLabeling}>
        Export to Label Studio
      </button>
      
      <button onClick={startTraining} disabled={training}>
        {training ? 'Training...' : 'Start Training'}
      </button>
    </div>
  );
};
```

#### 6.2 Enhanced OCR Editor
```javascript
// frontend/src/components/OCREditorWithLayoutLM.js

// Show confidence for each field
// Highlight predicted bounding boxes
// Allow manual correction
```

**Deliverables:**
- ‚¨ú Training UI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
- ‚¨ú Enhanced OCR Editor
- ‚¨ú Integration —Å Label Studio

---

## üì¶ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

### Backend

```python
# backend/requirements.txt

# Core
fastapi==0.104.1
uvicorn[standard]==0.24.0
sqlalchemy==2.0.23
alembic==1.12.1
celery==5.3.4
redis==5.0.1

# OCR & ML
paddlepaddle==2.5.0  # or paddlepaddle-gpu
paddleocr==2.7.0
transformers==4.35.0
torch==2.1.0  # or torch-gpu
pillow==10.1.0
numpy==1.24.0

# Validation
spacy==3.7.0
phonenumbers==8.13.0
email-validator==2.1.0

# Storage
psycopg2-binary==2.9.9
minio==7.2.0

# Utils
python-dotenv==1.0.0
pydantic==2.5.0
python-multipart==0.0.6
```

### Frontend

```json
// frontend/package.json
{
  "dependencies": {
    "react": "^18.2.0",
    "axios": "^1.6.0",
    "tailwindcss": "^3.3.0"
  }
}
```

### Infrastructure

```yaml
# docker-compose.yml

services:
  backend: ...
  frontend: ...
  postgres: ...
  redis: ...
  minio: ...
  label-studio: ...
```

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
fastapi-bizcard-crm-ready/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ integrations/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ocr/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ providers/
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ base.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ tesseract.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ paddle.py           ‚Üê NEW
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ google.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ parsio.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ manager.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ocr_service.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layoutlm_service.py         ‚Üê NEW
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validator_service.py        ‚Üê NEW
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training_service.py         ‚Üê NEW
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ storage_service.py          ‚Üê NEW
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ocr.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ training.py                 ‚Üê NEW
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ training.py                 ‚Üê NEW
‚îÇ   ‚îú‚îÄ‚îÄ models/                              ‚Üê NEW
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layoutlmv3_finetuned/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ checkpoints/
‚îÇ   ‚îî‚îÄ‚îÄ training_data/                       ‚Üê NEW
‚îÇ       ‚îî‚îÄ‚îÄ datasets/
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îî‚îÄ‚îÄ components/
‚îÇ           ‚îú‚îÄ‚îÄ OCREditorWithLayoutLM.js    ‚Üê NEW
‚îÇ           ‚îî‚îÄ‚îÄ TrainingPanel.js            ‚Üê NEW
‚îú‚îÄ‚îÄ label-studio-config.xml
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ OCR_ARCHITECTURE_MIGRATION_v2.md        ‚Üê THIS FILE
```

---

## üóìÔ∏è Roadmap

### Q1 2025 (Weeks 1-12)

| –ù–µ–¥–µ–ª—è | –≠—Ç–∞–ø | –ó–∞–¥–∞—á–∏ | –°—Ç–∞—Ç—É—Å |
|--------|------|--------|--------|
| 1-2 | –≠—Ç–∞–ø 0 | –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞, MinIO, Label Studio | üü° In Progress |
| 3-5 | –≠—Ç–∞–ø 1 | PaddleOCR Integration | ‚¨ú |
| 6-9 | –≠—Ç–∞–ø 2 | LayoutLMv3 Integration | ‚¨ú |
| 10-11 | –≠—Ç–∞–ø 3 | Validator & Post-processing | ‚¨ú |
| 12 | - | Testing & Benchmarking | ‚¨ú |

### Q2 2025 (Weeks 13-24)

| –ù–µ–¥–µ–ª—è | –≠—Ç–∞–ø | –ó–∞–¥–∞—á–∏ | –°—Ç–∞—Ç—É—Å |
|--------|------|--------|--------|
| 13-16 | –≠—Ç–∞–ø 4 | Training Pipeline | ‚¨ú |
| 17 | –≠—Ç–∞–ø 5 | MinIO Migration | ‚¨ú |
| 18-19 | –≠—Ç–∞–ø 6 | Frontend Integration | ‚¨ú |
| 20-22 | - | Annotate 500+ cards | ‚¨ú |
| 23 | - | Train production model | ‚¨ú |
| 24 | - | Deploy v2.0 to production | ‚¨ú |

---

## üìä –ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—Ö–∞

### –¶–µ–ª–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏

| –ú–µ—Ç—Ä–∏–∫–∞ | –¢–µ–∫—É—â–∏–π (v5.3.0) | –¶–µ–ª–µ–≤–æ–π (v2.0) | –°—Ç–∞—Ç—É—Å |
|---------|------------------|----------------|--------|
| **–¢–æ—á–Ω–æ—Å—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏—è** | ~70% | >95% | ‚¨ú |
| **–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏** | 2-5 —Å–µ–∫ | <3 —Å–µ–∫ | ‚¨ú |
| **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç API** | –í—ã—Å–æ–∫–∞—è | –ù–∏–∑–∫–∞—è | ‚¨ú |
| **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–±—É—á–µ–Ω–∏—è** | –ù–µ—Ç | –î–∞ | ‚¨ú |
| **Layout awareness** | –ù–µ—Ç | –î–∞ | ‚¨ú |

### KPI

- [ ] **Precision**: >95% –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—è
- [ ] **Recall**: >90% –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—è
- [ ] **F1-Score**: >92% overall
- [ ] **User corrections**: <5% –Ω–∞ 100 –≤–∏–∑–∏—Ç–æ–∫
- [ ] **Processing time**: <3 —Å–µ–∫—É–Ω–¥—ã/–≤–∏–∑–∏—Ç–∫–∞

---

## üîÑ Continuous Improvement

### Post-launch (Q3 2025+)

1. **Active Learning Loop**
   - –°–æ–±–∏—Ä–∞—Ç—å user corrections
   - –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å
   - A/B testing –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π

2. **Multi-language Support**
   - –î–æ–±–∞–≤–∏—Ç—å —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
   - –î–æ–±–∞–≤–∏—Ç—å –∫–∏—Ç–∞–π—Å–∫–∏–π —è–∑—ã–∫
   - –ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω—ã–µ –≤–∏–∑–∏—Ç–∫–∏

3. **Advanced Features**
   - Logo detection and extraction
   - Company recognition from logo
   - Social media links detection
   - Duplicate detection improvements

---

## üìö –°—Å—ã–ª–∫–∏ –∏ —Ä–µ—Å—É—Ä—Å—ã

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR)
- [LayoutLMv3](https://huggingface.co/docs/transformers/model_doc/layoutlmv3)
- [Label Studio](https://labelstud.io/guide/)
- [MinIO](https://min.io/docs/minio/linux/index.html)
- [HuggingFace Transformers](https://huggingface.co/docs/transformers/)

### Papers

- **LayoutLMv3**: [Microsoft Research Paper](https://arxiv.org/abs/2204.08387)
- **PaddleOCR**: [Baidu Research](https://github.com/PaddlePaddle/PaddleOCR)

### Tutorials

- [Fine-tuning LayoutLMv3](https://huggingface.co/docs/transformers/model_doc/layoutlmv3#fine-tuning-layoutlmv3)
- [Label Studio ML Backend](https://labelstud.io/guide/ml.html)

---

## ‚úÖ Next Steps

1. **Immediate (This Week)**
   - [ ] –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å MinIO
   - [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å Label Studio project
   - [ ] –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ø–µ—Ä–≤—É—é –ø–∞—Ä—Ç–∏—é –¥–∞–Ω–Ω—ã—Ö (100 –≤–∏–∑–∏—Ç–æ–∫)

2. **Short-term (Next 2 Weeks)**
   - [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å PaddleOCR Provider
   - [ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≤–∏–∑–∏—Ç–∫–∞—Ö
   - [ ] Benchmark vs Tesseract

3. **Medium-term (Next Month)**
   - [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å LayoutLMv3 Service
   - [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å PaddleOCR
   - [ ] –ù–∞—á–∞—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö

---

**–í–µ—Ä—Å–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞**: 2.0.0  
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ**: October 26, 2025  
**–ê–≤—Ç–æ—Ä**: AI Assistant  
**–°—Ç–∞—Ç—É—Å**: üöÄ Planning Phase

---

*–≠—Ç–æ—Ç –ø–ª–∞–Ω –º–∏–≥—Ä–∞—Ü–∏–∏ —è–≤–ª—è–µ—Ç—Å—è –∂–∏–≤—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º –∏ –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª—è—Ç—å—Å—è –ø–æ –º–µ—Ä–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø—Ä–æ–µ–∫—Ç–∞.*

